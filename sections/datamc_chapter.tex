\section{Data, Monte Carlo, and HGam Pre-selection} \label{sec:DataMC}

\subsection{Data} \label{sec:Data}

In both Run-2 HGam analyses discussed in this dissertation, we use the full LHC Run-2 dataset, consisting of $139.0 \plusminus 2.4 fb^{-1}$ of proton-proton collisions with a center of mass energy $\sqrt{s} = 13 TeV$ recorded by the ATLAS detector between 2015 and 2018 \ref{Jennet106}. Figure \ref{fig:datalumi} shows the instantaneous luminosity gathered by the detector as a function of time; figure \ref{fig:pileup} shows the pileup as a function of time. 

Figure: datalumi
Figure: pileup


The trigger used to select events is the diphoton trigger HLT_g35_loose_g25_loose (for 2015-2016 data) and HLT_g35_medium_g25_medium (for 2017-2018 data). Both triggers require two photon candidates, one with a transverse energy $E_{T}$ of at least 35 GeV and the other with transverse energy of at least 25 GeV. The 2015-2016 trigger requires two photons that pass the "loose" ID requirement, while the 2017-2018 trigger requires two photons that pass the "medium" ID requirement (the cut was tightened due to increased luminosity and pileup). The trigger was calibrated using radiative Z decays, and is observed to be greater than 95\% efficient for each photon as long as it is 5 GeV above the trigger threshold \ref:cite{TriggerPerformance}.

Figure: EffCurve

\subsection{Higgs Preselection and Data CRs} \label{sec:Preselection} 

In both analyses discussed in this dissertation, we use the following preselection to define the $H \rightarrow \gamma \gamma$ signal region. These requirements are applied for both data and Monte Carlo simulation. 

\begin{itemize}
\item $\gamma\gamma Preselection$: The event is required to contain two photons passing the loose isolation and ID requirements.
\item $PV$: At least one primary vertex is required to be identified in the event.
\item $Trigger-Matching$: The leading two photons observed are required to match those identified by the trigger.
\item $Relative p_{T}$: The leading and subleading photons are required to have $p_{T}/m\gamma\gamma$ larger than 0.35 and 0.25, respectively.
\item $TI$: For events in the signal-region, we require both photons to pass the "Tight" Photon ID and Isolation requirements (for events in the 'NTI' data control region, this selection criterion is ignored). 
\item $Invariant Mass$: The invariant mass of the diphoton system must satisfy $105 GeV < m_{\gamma\gamma} < 160 GeV$
\end{itemize}

In order to accurately model the continuum diphoton background, it is often useful to invert the $TI$ requirement- that is, we construct a data sample consisting of those events passing all other preselections, but for which one or more photons does not pass either or both of the "tight" isolation and ID requirements. Data control samples in this not-tight-isolated "$NTI$" region allow us to model the kinematic properties of objects in the event other than the diphoton system, such as top quark jet variables, with some amount of accuracy.

Additionally, it is useful to consider the $TI$ or $NTI$ data sidebands- this consists of the set of events passing either $TI$ or $NTI$ selection with either $105 GeV < m_{\gamma\gamma} < 120 GeV$ or $130 GeV < m_{\gamma\gamma} < 160 GeV$. This allows us to model the shape of the background while safely away from the Higgs signal peak near 125 GeV. This is detailed further in the subsequent analysis-specific chapters.

\subsection{Nominal and Alternative Monte Carlo Samples} \label{sec:NominalMC} 

In order to generate Monte Carlo simulated events, several software programs must work in concert. In a real physics event, different proton constituents (usually gluons or quarks, often called "partons"), interact with one another in a process called a hard scatter to produce new particles. 

To simulate such a collision, the quantum field-theoretic "matrix element" that governs the dynamics of the hard-scatter process must be calculated, the momentum distributions of the individual partons must be modelled using Parton Distribution Functions (or PDFs), and the decay showers of any final-state hadrons produced in the event must be dynamically modelled. Additionally, the dynamics of proton constituents not contributing to the hard scatter, called the "underlying event", must also be simulated. Because showering and underlying event processes are difficult to accurately model, they are "tuned" on the data using a variety of particular parameter sets \ref{cite:tunes}. 

A list of the versions and purposes of the Monte Carlo generator tools is detailed in Table \ref{Table:MCTools}. 

\begin{table}[h]
    \centering
    \begin{tabular}{cccc}
                Purpose & Name & Version & References \\ \hline
				Matrix Element &&& \\                
                & MadGraph5_aMC@NLO & \ref{cite:MG5} \ref{cite:aMCNLO} \\
                & Powheg & \ref{cite:Powheg1} \ref{cite:Powheg2} \ref{cite:Powheg3} \\ \hline
                Showering + Matrix Element &&& \\              
                & Pythia8 & \ref{cite:Pythia1} \ref{cite:Pythia2}  
                & Herwig7 & \ref{cite:Herwig1} \ref{cite:Herwig2}
                Hadronization &&& \\              
                & EvtGen & \ref{cite:EvGen}  
                Matrix Element+Showering+Hadronization &&& \\              
                & Sherpa & \ref{cite:Sherpa1} \ref{cite:Sherpa2} \ref{cite:Sherpa3} \ref{cite:Sherpa4}  
    \end{tabular}
    \caption{Tools used for Monte Carlo generation in the analyses detailed in this dissertation.}
    \label{MCTools}
\end{table}

After generation, Monte Carlo simulations are then passed through the Geant4 software package \ref{Geant4} to simulate the detector response. After this, the events are passed through the same object-reconstruction software used for data events \ref{arXiv: 1005.4568}. All Monte Carlo samples used in this dissertation are generated using the Geant4 full simulation, with the exception of the QCD continuum diphoton samples used for background modelling, which were treated using the GEANT4 fast simulation settings due to the number of events generated. For all MC samples, pile-up interactions were simulated by overlaying each Monte Carlo event with a different number of minimum-bias events simulated using Pythia 8.186 \ref{cite:Pythia} with the ATLAS "A3" tune \ref{cite:A3}.

In all Monte Carlo simulations, the Higgs mass was set to 125 GeV and the decay width was set to 407MeV \ref{cite:HiggsWidth}. All samples described include the small contribution from Dalitz decays (that is, decays in which one photon converts into two real final-state leptons), which is accounted for in the normalization of the samples. For all Monte Carlo samples generated using Madgraph5_aMC@NLO, the renormalization ($μ_{R}$) and factorization ($μ_{F}$) scales are defined as the scalar sum of the transverse masses of all final-state particles divided by two (i.e. $H_{T}/2$), and the top and W boson decays are handled by MadSpin \ref{cite:MadSpin} in order to ensure the correct treatment of the spin correlations of the decay products.

For all simulated samples, several corrections are applied to ensure the simulated samples correspond to data, including a beam-spot width correction, photon shower-shape and calorimetric isolation corrections, energy scale and resolution corrections, photon identification and isolation corrections, jet selection efficiency corrections, and electron and muon identification, reconstruction and isolation corrections.

\begin{table}[h!]
  \centering
  \resizebox{\columnwidth}{!}{%
	\begin{tabular}{ |c|c|c|c| }
    	Prod. Mode   &      Generator       & PDF (Matrix Element) & PDF+Tune (Parton Shower)\\ 
		\toprule
		    \ggH    &  \NNLOPS + \PYTHIA   & \PDFLHC  &  AZNLOCTEQ6   \\
			\VBF    &      \POWPYTHIA      & \PDFLHC  &  AZNLOCTEQ6   \\
  			$W^{+}H$  &      \POWPYTHIA      & \PDFLHC  &  AZNLOCTEQ6   \\
			$W^{-}H$  &      \POWPYTHIA      & \PDFLHC  &  AZNLOCTEQ6   \\
			$qq\to ZH$ &      \POWPYTHIA      & \PDFLHC  &  AZNLOCTEQ6   \\
			$gg\to ZH$ &      \POWPYTHIA      & \PDFLHC  &  AZNLOCTEQ6   \\
			\bbH    &      \POWPYTHIA      & \PDFLHC  &  A14NNPDF23   \\
			\ttH    &      \POWPYTHIA      & \PDFLHC  &  A14NNPDF23   \\
			\ttH    & \MGMCatNLO + \PYTHIA &  \NNPDF  &  A14NNPDF23   \\
			\tHjb   & \MGMCatNLO + \PYTHIA &  \NNPDF  &  A14NNPDF23   \\
			\tHW    & \MGMCatNLO + \PYTHIA &  \NNPDF  &  A14NNPDF23   \\
			
		\bottomrule
	\end{tabular}
	}
  \caption{Summary of nominal signal samples}
  \label{tab:signal_samples_pyt}
\end{table}

Nominal gluon-gluon fusion events are simulated using the Powheg NNLOPS tool \ref{cite:NNLOPS} using the PDF4LHC15 PDF set \ref{cite:PDF4LHC}, while the nominal $VBF$, $WH$, $ZH$, and $ggZH$ are all generated using the Powheg generator with the PDF4LHC15 PDF set. Showering is performed with Pythia using the AZNLO tune \ref{cite:AZNLO} and the CTEQ6 PDF set \ref{cite:CTEQ6} for these samples. Nominal Standard-Model $ttH$ and $bbH$ samples are generated using the PowhegBOX tool \ref{cite:PowhegBox} using the PDF4LHC15 PDF set; for these samples, showering is performed with Pythia using the A14 tune \ref{cite:A14} and the NNPDF23 PDF set \ref{cite:NNPDF23}. Nominal $tWH$ and $tHjb$ samples are generated using the Madgraph5_aMC@NLO generator with the NNPDF30 PDF Set \ref{cite:NNPDF30}, and are showered using Pythia with the A14 tune and the NNPDF23 PDF set. $tWH$ samples are generated using the five-flavor PDF scheme, while $tHjb$ samples are generated using the four-flavor PDF scheme. At first order, NLO corrections to the $tWH$ process contain final-state bottom quark jets that thus lead to interference with the more-common $ttH$ process \ref{cite:DemartintWH}; to resolve this, a diagram subtraction method is used \ref{cite:subtraction}.
Additionally, a $ttH$ sample is generated using the Madgraph5_aMC@NLO generator with the NNPDF30 PDF Set \ref{cite:NNPDF30} for use with the dedicated $ttH CP$ samples, in order to confirm the validity of the effective field theory model used to generate them.

Alternative Standard-Model samples are developed using Herwig for showering rather than Pythia, in order to evaluate the parton-showering uncertainty. The matrix element generators and PDFs are all the same as for the nominal samples, with the exception of the VBF sample, for which generator weights were unable to be included using the Herwig showering tool (and thus the NNPDF30 PDF is quoted for both the generator and the showering tool). $ggH$, $VBF$, $VH$, $tWH$, $tHjb$ and the supplementary Madgraph5_aMC@NLO $ttH$ sample are all showered using the H7P1 Tune \ref{cite:H7p1}, and the Powheg $ttH$ sample is showered using the \ref{cite:H7UE} tune.

Additionally, a supplementary $ggH$ sample is generated using Madgraph5_aMC@NLO containing an additional two partons at the matrix element stage. To avoid double-counting events with additional final-state partons, the "FxFx" merging scheme is employed. This sample is showered with Pythia using the NNPDF30 PDF and the A14 tune.
 
\begin{table}[h!]
  \centering
  \resizebox{\columnwidth}{!}{%
    \begin{tabular}{ |c|c|c|c| }
    	Prod. Mode   &      Generator       & PDF (Matrix Element) & PDF+Tune (Parton Shower)\\ 
    	\toprule
		\ggH    &  \NNLOPS + \HERWIG   & \PDFLHC  &  \NNPDF+H7p1  \\
		\VBF    &  \POWHEG + \HERWIG   &  \NNPDF  &  \NNPDF+H7p1  \\
		$W^{+}H$  &  \POWHEG + \HERWIG   & \PDFLHC  &  \NNPDF+H7p1  \\
		$W^{-}H$  &  \POWHEG + \HERWIG   & \PDFLHC  &  \NNPDF+H7p1  \\
		$qq\to ZH$ &  \POWHEG + \HERWIG   & \PDFLHC  &  \NNPDF+H7p1  \\
		$gg\to ZH$ &  \POWHEG + \HERWIG   & \PDFLHC  &  \NNPDF+H7p1  \\
		\ttH    &  \POWHEG + \HERWIG   & \PDFLHC  &  \NNPDF+H7UE  \\
		\ttH    & \MGMCatNLO + \HERWIG &  \NNPDF  &  \NNPDF+H7p1   \\
		\tHbj    & \MGMCatNLO + \HERWIG &  \NNPDF  &     \NNPDF+H7p1      \\
		\tHW    & \MGMCatNLO + \HERWIG &  \NNPDF  &     \NNPDF+H7p1      \\
		\ggH    & \MGMCatNLO + \PYTHIA & \NNPDF   &     \NNPDF+A14       \\
    	\bottomrule
    \end{tabular}
  }
  \caption{Summary of alternative signal samples}
  \label{tab:signal_samples_herwig}
\end{table}  

The cross-sections for all Higgs processes are normalized to the state-of-the-art precision measurements discussed in \ref{cite:Yellowreport} using K-factor scaling factors. The accuracy of the cross-sections is N3LO QCD $+$ NLO Electroweak for $ggH$, NNLO $QCD$ $+$ NLO Electroweak for $VBF$ and $VH$, and NLO QCD $+$ NLO Electroweak for $ttH$, while $tHjb$ and $tWH$ are produced at NLO QCD with no electroweak correction. Additionally, samples are normalized to account for the $H \rightarrow \gamma \gamma$ branching ratio of $2.270 \times 10^{-3}$ calculated with HDECAY \ref{HDecay} and PROPHECY4F \ref{Prophecy}.

\begin{table}[h!]
  \centering
  \resizebox{0.25\columnwidth}{!}{%
    \begin{tabular}{ c|l }
      Prod. Mode & {XSxBR [pb]}   \\
      \hline
    	 \ggH       & 0.1101404   \\
    	 \VBF       & 0.00857833  \\
    	 $W^{+}H$   & 0.00190226  \\
    	 $W^{-}H$   & 0.00120605  \\
    	 $qq\to ZH$ & 0.001724519 \\
    	 $gg\to ZH$ & 0.000278529 \\
    	 \ttH       & 0.001149755 \\
    	 \tHbj      & 0.00016857  \\
    	 \tHW       & 3.44359e-05 \\
         \bbH       & 0.00110390  \\
    	\bottomrule
    \end{tabular}
  }
  \caption{Cross sections times branching ratio values used to normalize each production mode. The values correspond to the state-of-the-art predictions and are taken from the CERN Yellow Report \ref{cite:yellowreport}.}
  \label{tab:signal_samples_norm}
\end{table}  

The background for $H \rightarrow \gamma \gamma$ events is generally treated as a smoothly-falling, continuous distribution in diphoton mass $m_{\gamma \gamma}$. It is comprised of non-Higgs events containing real final-state or initial-state radiated photons, as well as hadronic jets that behave like photons. To model this, a functional-form based data-driven method is used; however, Monte Carlo templates are nonetheless used to facilitate and validate the background modelling.

Both QCD continuum $\gamma\gamma$ +jets production and the various $V\gamma\gamma \rightarrow ll\gamma\gamma$ samples are simulated at leading order in QCD using the Sherpa event generator with the CT10 PDF set \ref{cite:CT10}. Showering is performed using the default Sherpa showering tool. 

$t\bar{t}\gamma\gamma$, one of the leading backgrounds in top-enriched regions, is simulated using Madgraph5_aMC@NLO with the NNPDF30 PDF set. It is showered using Pythia and tuned using the A14 tune.


\begin{table}[h!]
  \centering
  \resizebox{\columnwidth}{!}{%
  \begin{tabular}{|c|c|c|c|}
  	 Prod. Mode   &      Generator       & PDF (Matrix Element) & PDF+Tune (Parton Shower)\\ 
  	\toprule
  	$\gamma\gamma+$0,1(NLO),2,3(LO), \myy $\in$ 50-90 \GeV  & \SHERPA & \CT10 & \SHERPA & \CT10\\
 $\gamma\gamma+$0,1(NLO),2,3(LO), \myy $\in$ 90-175 \GeV & \SHERPA & \CT10 & \SHERPA & \CT10\\
         $ee\gamma\gamma$; $\myy>\SI{80}{\GeV}$          & \SHERPA & \CT10 & \SHERPA & \CT10\\
       $\mu\mu\gamma\gamma$; $\myy>\SI{80}{\GeV}$        & \SHERPA & \CT10 & \SHERPA & \CT10\\
      $\tau\tau\gamma\gamma$; $\myy>\SI{80}{\GeV}$       & \SHERPA & \CT10 & \SHERPA & \CT10\\
      $\nu\nu\gamma\gamma$; $\myy>\SI{80}{\GeV}$         & \SHERPA & \CT10 & \SHERPA & \CT10\\
        $e\nu\gamma\gamma$; $\myy>\SI{80}{\GeV}$         & \SHERPA & \CT10 & \SHERPA & \CT10\\
       $\mu\nu\gamma\gamma$; $\myy>\SI{80}{\GeV}$        & \SHERPA & \CT10 & \SHERPA & \CT10\\
       $\tau\nu\gamma\gamma$; $\myy>\SI{80}{\GeV}$       & \SHERPA & \CT10 & \SHERPA & \CT10\\
            $t\bar{t}\gamma\gamma$ (noallhad)            & \MGMCatNLO & \NNPDF & \PYTHIA & \NNPDF+A14       \\
             $t\bar{t}\gamma\gamma$ (allhad)             & \MGMCatNLO & \NNPDF & \PYTHIA & \NNPDF+A14       \\ 
  	\bottomrule
  \end{tabular}
  }
\caption{Summary of nominal background samples}
\label{tab:bckg_samples}
\end{table}  

\subsection{ttHCP Monte Carlo Samples} \label{sec:ttHCPMC} 

In the $ttH CP$ analysis, an Effective Field Theory (EFT) setting a cutoff scale of 1 TeV, below which no new BSM particles coupling to the Higgs exist, is used to generate Monte Carlo samples. The EFT used is the Higgs Characterization (HC) model \ref{cite: HC}, implemented in the  MadGraph5_aMC@NLO generator \ref{cite: Madgraph}. As previously mentioned, the top-Higgs interaction term of the Lagrangian in the presence of CP-violation can be parameterized as

\begin{equation}
\mathcal{L} = \kappa_{t} g_{t} \bar{t} (cos(\alpha)+ sin(\alpha) i \gamma^{5} )th
\end{equation}

where $g_{t} = \frac{-m_{t}}{v} = \frac{-173.26 GeV}{246 GeV} = -0.703$ , $\kappa_{t}$ is the dimensionless coupling-strength term ($\kappa_{t}= 1$ in the Standard Model), and $\alpha$ is an angle that parameterizes the CP-mixing strength ($\alpha = 0$ in the Standard Model, $\alpha = \frac{\pi}{2}$ in the fully CP-odd case). The treatment of the $H \rightarrow \gamma \gamma$ and $ggH$ dependence on $\alpha$ is handled in several different ways, as discussed in \ref{sec:ttHCPresults}.

ttH tHjb tWH

ggH


table

table

As in the nominal case, $t\bar{t}H$ and $tWH$ samples are generated using the five-flavor scheme, while the four-flavor scheme is used for the $tHjb$ process. The Standard Model cross-sections for all process are normalized to those given in the CERN Higgs Yellow Report 4 \ref{cite:yellowreport}, in which fixed scales and the five-flavor scheme are used. Those cross-sections are calculated at NLO QCD accuracy (without electroweak correction) for the $tHjb$ and $tWH$ processes, while $t\bar{t}H$ is calculated at both NLO QCD and NLO Electroweak accuracies. K-factors are then computed to scale the Higgs Characterization Monte Carlo cross-sections to the Yellow Report cross-sections. The obtained K-factors are shown to be similar for different CP mixing angles; thus, the K-factors derived for the SM case can be safely used for the various samples with different $\alpha$ values. 