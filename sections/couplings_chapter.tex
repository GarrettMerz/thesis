
As high-energy physics enters the era of Higgs precision measurement, targeting the $H \rightarrow \gamma \gamma$ decay channel offers a valuable avenue for probing Higgs couplings and production modes. Though its branching ratio is rather small (0.227\% \ref{cite:HiggsBR}), the ATLAS detector's excellent photon reconstruction and energy resolution capabilities provide a very clean avenue for signal and background reconstruction in this channel, leading to high purity compared to other channels.

The Couplings analysis is optimized to measure the cross-sections in a number of STXS regions. While an interpretation using the kappa-framework and EFT methods is currently under development at the time of this writing, the cross-sections in each of the STXS categories are reported as a targeted observable.

The preselection at both object and event level is detailed in sections \ref{sec:methods_chapter} and \ref{sec:datamc_chapter}.

\section{Categorization} \label{sec:Categorization} 

A categorization scheme is developed to target the STXS truth bins. The categorization is an improvement over that of the previous $80 fb^{-1}$ Coupling analysis, which sorted events into categories based on a "greedy" sequential approach \ref{cite:couplings80fb}. In the new analysis, which uses the full $139 fb^{-1}$ of data gathered by ATLAS, events are instead sorted into categories based on a unified technique that considers a number of their properties simultaneously to determine the optimal categorization scheme.

Categorization proceeds in two primary steps. First, a multiclassifier Boosted Decision Tree (BDT) is trained to target STXS truth bins. A multiclassifier BDT differs from a binary BDT in that it outputs a vector discriminant corresponding to the probability that an event falls into one of a number of different regions, rather than a binary discriminant simply classifying an event as signal or background. After events are assigned into different classes targeting the STXS truth bins, they are subdivided into categories using a second binary BDT trained in each class, designed to separate Higgs signal from continuum background. The process of the BDT categorization scheme is shown in the cartoon in figure XXX.

The inputs to all BDTs are kinematic variables for the various objects in an event. In order to avoid sculpting of the shapes used in the statistical analysis, any variable found to be linearly correlated by 5\% or more with $m_{\gamma \gamma}$ in the signal or background training samples is removed from the list of inputs. The list of all variables used as input to both the multiclassifier BDT and the binary BDTs is given in Table XXX.

To train the multiclassifier BDT, all signal samples are merged ($ggF$, $VH$, $VBF$, $ttH$, $tH$). A weight is then applied to each event such that all processes have equal yields in the training sample (that is, so processes such as $tH$ with a small cross-section are not underrepresented). The output of the multiclassifier BDT is a 44-dimensional vector discriminant with an index $y_{i}$ for each truth bin; these indices are then converted into class probabilities $z_{i}$ using a softmax function: $z_{i} = e^{y_{i}}/{\Sigma_{j}e^{y_{j}}}$. The BDT training is performed by minimizing the cross-entropy of the $z_{i}$ using the LightGBM package \ref{cite:LightGBM}.

After this, a per-class weight is calculated for each category using a so-called 'D-optimality' procedure. This is done iteratively: first, weights are initialized to $w_{i} = 1$. Second, events are classified based on the value of $w_{i}z_{i}$. An Asimov dataset \ref{cite:Asimov} is then created using the signal samples in each category, normalized to their Standard Model cross-sections and simulated continuum background ($\gamma\gamma$, $V\gamma\gamma$, and $tt\gamma\gamma$) scaled to the TI sidebands in the region $95 GeV < m_{\gamma \gamma} < 105 GeV$. A simplified version of the overall fit is then performed, using an exponential function if the total scaled background yield is determined to be less than 400 events and an ExpPoly2 function otherwise. This Asimov dataset is then fitted, leading to a covariance matrix C of the event yields in each region. The weights are then iteratively updated using the Powell algorithm \ref{cite:Powell1}, \ref{cite:Powell2} until the determinant of the covariance matrix is minimized. By minimizing the determinant of this covariance matrix, the information gain from a particular classification scheme is maximized \ref{cite:Linley}. In an experimental sense, this corresponds to higher signal purity in the classes corresponding to rare processes such as $ttH$ and $tH$. These final weights are multiplied by the softmax function output; events are classified based on their maximum value of $w_{i}z_{i}$. This produces 44 classes, one for each STXS region. The multiclassifier output for four representative classes is shown in figure XXX.


After being sorted into a multiclass region, events are then passed through a binary signal-or-background BDT that is trained independently for each category. For classes targeting $ggH$ and $qq' \rightarrow Hqq'$ (that is, $VBF$ and hadronic $VH$), a binary BDT is trained for each class, using the targeted process as signal and the other Higgs processes and continuum diphoton production as background. However, a single binary BDT is trained for all leptonic $VH$ classes and another is trained for all $ttH+tH$ classes due to a lack of training statistics if no merging is applied. For the leptonic $VH$ and the $ttH+tH$ binary BDTs, NTI data is used to model the background.

In each class, events are then sorted into a final set of 88 total categories based on the binary BDT scores. Each of the initial 44 classes is subdivided into one, two, or three categories, depending on the targeted process. The category boundaries are found by scanning all possible sets of boundaries in binary BDT score and choosing the set that maximizes the Poisson Number-Counting Significance, defined as $\sqrt{2((S+B)\ln(1+S/B)-S)}$ as in section \ref{sec:ttHCP_chapter}. The signal S for this significance metric is the yield of the targeted STXS bin, while the background is comprised of both a continuum diphoton contribution calculated from Sherpa Monte Carlo events scaled to the TI sidebands in the region $95 GeV < m_{\gamma \gamma} < 105 GeV$ and Higgs events from other STXS bins. A class is split into two categories if it able to achieve a significance gain of more than 5\% over the single-category case, and a further third category if it able to achieve an additional 5\% significance gain over the two-category case by doing so. Some events may have binary BDT scores causing them to fall outside the subdivided regions; for these events, three 'unselected' categories (one for $qq \rightarrow H l \nu$, one for $qq \rightarrow ZH$, and one for $ttH+tH$) are created. The binary BDT output for four representative categories is shown in figure XXX.

The expected yield, purity ($S/(S+B)$), and significance for each category is given in table XXX. The correspondence between the reconstructed categories and the STXS truth bins is given in Figure XXX.

\section{Signal and Background Modelling} \label{sec:SignalBackground} 

As in the CP analysis, a profile likelihood ratio fit is conducted simultaneously in all categories and a signal strength parameter is extracted.

Signal in each category is modelled using a Double-Sided Crystal Ball function, fit to Higgs-signal Monte Carlo. The list of all fitted Double-Sided Crystal Ball parameters is given in table XXX. The Higgs mass is fixed to the run-1 measured value of $125.09 GeV \pm 0.21 GeV(stat) \pm 0.1 GeV(syst)$ \ref{cite:HiggsMass}.

Similarly, background is modelled using the spurious signal test. As detailed in section \ref{sec:sigbkgparam}, in the $ggH$ and $qq
 \rightarrow Hqq'$ categories, the templates for the spurious signal study are conducted from Sherpa diphoton samples reweighted to model the proportional contributions of $\gamma \gamma$, $\gamma j$ and $jj$ events consisting of both true and fake photons in each category. In the leptonic $VH$ and $ttH+tH$ regions, however, the $\gamma j$ and $jj$ contributions are small enough to be neglected, so $V\gamma\gamma$ and $tt\gamma\gamma$ Monte Carlo respectively are used for the templates. In the low-stat categories, a Wald test is used to select the functional form. The spurious signal values and the choice of function are given in table XXX.

A novel Gaussian Process Regression procedure is implemented to smooth the templates and reduce the spurious signal uncertainty, as expanded upon in Appendix \ref{app:GPR} and validated in Appendix \ref{app:gpr_validation}. This process is not implemented in the results quoted in this chapter, but is in preparation for an iteration of this analysis with an updated categorization scheme that is currently being prepared for publication. Sample background templates in two representative categories are shown in Figure XXX; an expanded set of templates both with and without the GPR procedure applied are shown in Appendix \ref{app:GPR}.

\section{Systematic Uncertainties} \label{sec:Systematics} 

Systematics follow a similar prescription as in the CP analysis. They can be broadly split up into two sources, experimental and theoretical, and can influence the overall yield and distribution shapes for different processes, or cause migration between STXS bins. 

Due to the large number of nuisance parameters, a nuisance parameter is removed from consideration if it has an effect of $< 0.3\%$ when varied up or down by one standard deviation.

\subsection{Theory Systematics} \label{subsec:Theorysysts}

Theory systematics can broadly be broken down into perturbative QCD scale uncertainties, PDF + $\alpha_{S}$ uncertainties, uncertainty on the $H \rightarrow \gamma \gamma$ branching ratio, QCD effects in the soft (low-energy) regime, and final state heavy-flavor jet uncertainty.

Because the $ggF$ process is being measured specifically in fine STXS bins and not being selected against as in the CP analysis, and because the final-state jet multiplicity may vary, it is not enough to simply vary the QCD renormalization and factorization scales to account for QCD effects in $ggF$, as in the CP analysis. Thus, for $ggF$, the QCD uncertainty is broken up into 14 individual nuisance parameters, including QCD resummation and factorization scale uncertainties, migration uncertainties across different jet-multiplicity regimes, and migration between STXS bins with differing values of $p_{T}^{Hjj}$ and $m_{jj}$. Additionally, a comparison of acceptance and efficiency factors between the nominal $ggF$ sample and the alternative MadGraph5\_aMC@NLO sample is made, and the differences are considered asadditional $ggF$ modeling uncertainties.

Additional QCD uncertainties on $VH$ processes are modelled, for similar reasons as for $ggH$: for each of $WH$, $qq/qg /rightarrow ZH$, and $gg \rightarrow ZH$, one source of overall yield uncertainty, four sources of $p_{T}^{V}$ modeling uncertainty, and two sources of jet multiplicity modeling uncertainty are accounted for. For $qq' \rightarrow H qq'$ processes, a similar set of uncertainty sources are identified: one for overall yield variation, two for modeling of the jet multiplicity and $p_{T}^{Hjj}$ distributions, one for migration between $p_{T}^{H} < 200$ GeV and $p_{T}^{H} > 200$ GeV, and six for the modeling of the $m_{jj}$ distribution.

For $ttH$ and $tH$, one nuisance parameter is introduced for the yield and six are introduced for the $p_{T}^{H}$ distribution.

The value of the various QCD scale uncertainties varies between categories, but is found to have an effect of between 5\% and 25\%.

Parton showering uncertainty is evaluated by comparing the Pythia8 and Herwig7 Monte Carlo samples. Doing so leads to six nuisance parameters in each category; the effect of each of these is found to be approximately 10\% or less.

The PDF and $\alpha_{S}$ uncertainties are evaluated using the PDF4LHC15 \ref{cite:PDF4LHC15} prescription, using a matrix method designed to facilitate easier combination with other Higgs decay channels. Effects are typically very small compared to other sources of theory uncertainty.

As in the CP analysis, in categories targeting $ttH$ and $tH$, we apply a 100\% yield uncertainty on the $ggF$, $VBF$, and $VH$ processes, due to poor modelling of these processes in events containing final-state hadrons. This is supported by measurements in $H \rightarrow ZZ^{*}\rightarrow 4l$ \ref{cite:HZZ4l}, $t\bar{t}b\bar{b}$ \ref{cite:ttbb}, and $Vb$ \ref{cite:Vb}.

The theoretical uncertainties on the Higgs boson production cross section and the $H \rightarrow \gamma \gamma$ decay branching ratio are not used in the measurements. However, the $H \rightarrow \gamma \gamma$ decay branching ratio has an uncertainty of 1.6\%, according to the HDECAY and PROPHECY4F programs.

The largest theoretical systematic is the parton showering and underlying event modelling, and its impact on the measured cross sections can be up to 11\% in some $VBF$ categories. 

\subsection{Experimental Systematics} \label{subsec:Experimentalsysts}

Experimental systematics can broadly be broken up into two categories, those influencing or resulting from the shape of functional forms used in the fit (photon energy scale, photon energy resolution) and those influencing the overall yield (due to object reconstruction effects, luminosity, Higgs mass mismeasurement, and pileup reweighting).

The photon energy scale and resolution are included as response functions on \mu_{CB} and \sigma_{CB}, respectively. They are extracted for each individual category from Monte Carlo samples with these parameters varied and are treated as uncorrelated variations across categories. For the photon energy scale, the nominal mean is compared with that of the varied sample, while for the photon energy resolution, the inter-quartile range is compared across samples. A fully-decorrelated model is used for photon energy resolution and a merged scheme is used for photon energy scale, due to the minimal sensitivity of the analysis to scale variations. Scale uncertainties are treated with a Gaussian constraint, while resolution uncertainties are treated with asymmetric constraints. Their impact is between 1\% and 8\%, depending on the category.

85 additional nuisance parameters are introduced to model yield variations. These include jet reconstruction uncertainties such as jet flavor composition, flavor response, jet modelling, jet topology, and jet energy resolution \ref{cite:coups127} as well as b-tagging efficiency \ref{cite:coups130}. Photon isolation and identification efficiency uncertainties \ref{cite:coups116}, spurious signal, trigger efficiency \ref{cite:coups27}, and luminosity uncertainty (obtained using the LUCID-2 detector) \ref{cite:LUCID} are also parameterized in this way. These systematics are treated as correlated, and are treated with either asymmetric or log-normal constraints.

Spurious signal uncertainty ranges from 10\% to 99\% of the statistical uncertainty in categories, depending on statistics. It is considered to be uncorrelated across categories.

Pileup uncertainty is modelled by varying the cross-section used to reweight pileup interactions from Monte Carlo to the data up or down by 9\%. 

For $ggH$ and $VH$ categories, the leading experimental systematic uncertainty arises from the spurious signal, with an impact of around 4\% on the cross-section. For the $VBF$ and $ttH+tH$, the leading experimental uncertainty is jet modelling, and with an impact that can rise to as large as 6\%.

The table of all systematics in the five-production-mode fit (combining STXS bins) is given in table XXX. 

\section{Results} \label{sec:Results}

Three primary results are reported: First, an overall production cross-section; second, cross-sections for each of the five main individual production modes ($ggF+bbH$, $VBF$, $WH$, $ZH$, and $ttH+tH$); and third, cross-sections in each of the STXS bins. At the time of this writing, further work is being performed in order to prepare additional results that will interpret these cross-sections in terms of both the Kappa-Framework and in terms of constraints on Effective Field Theory (EFT) observables.

\subsection{Cross-Sections} \label{sec:Xsecs}

The overall cross-section is measured by profiling a single parameter, the cross-section times branching ratio ($\sigma \times B_{\gamma \gamma}$), which scales with the yield in each category. All 88 categories are fit simultaneously. The requirement $|y_{H}|<2.5$ is applied on both the 

Figure XXX shoes the $m_{\gamma\gamma}$ distribution across categories, weighted by the ratio $ln(1+\frac{S}{B})$ where S and B are the signal and background yields in the smallest $m_{\gamma\gamma}$ window measured to contain 90\% of signal events. The choice of this weight is designed to illustrate the impact of more signal-dominated categories in a manner similar to how they enter into the likelihood fit. 
The overall cross-section is measured to be:

\begin{equation}
(\sigma \times B_{\gamma \gamma})_{obs} =127 \pm 10 fb=127 \pm 7(stat.) \pm 7(syst.)fb
\end{equation}

with an expectation measured using post-fit Asimov data of:

\begin{equation}
(\sigma \times B_{\gamma \gamma})_{exp} =115 \pm 5 fb
\end{equation}

For the five-production mode model, $(\sigma \times B_{\gamma \gamma})$ is measured separately for each production mode: $ggF+bbH$, $VBF$, $ZH$, $WH$, and $ttH+tH$. The $m_{\gamma\gamma}$ distribution in these categories, weighted by the ratio $ln(1+\frac{S}{B})$, are shown in Figure XXX. The measured cross-sections times the diphoton branching ratio are depicted in Table XXX and Figure XXX. The full correlations (and stat-only correlations) between categories are depicted in Figure XXX. The observed (expected) significance values for the $VBF$, $WH$, and $ttH+tH$ processes are 7.5 (6.1) $\sigma$, 5.6 (2.8) $\sigma$, and 4.7 (5.0) $\sigma$, respectively. The expected significance for the $ZH$ process is 1.7 $\sigma$, and no excess over the background is observed in data. Together, these correspond to a roughly 1.9 $\sigma$ deviation from the SM.

The reason for this discrepancy is the strong anticorrelation observed between the $WH$ and $ZH$ processes: if these are combined into one $VH$ production mode, the cross-section becomes $(\sigma_{VH})_{obs} = 5.9 \pm 1.4fb = 5.9 \pm 1.4(stat.) \pm 0.4(syst.)fb$ compared to the SM expectation of $(\sigma_{VH})_{exp}=4.53 \pm 0.12fb$. This corresponds to no excess with respect to the SM result.

The anticorrelation is because the leptonic $ZH$ categories suffer from substantial $WH$ contamination and an excess is observed in the leptonic $WH$ categories, so when $\mu_{WH}$ is higher, in order to converge, the fit must overestimate the contribution of $WH$ and underestimate the contribution of $ZH$. In order to rectify this, at the time of this writing, a new categorization scheme is being devised that will introduce a high-purity leptonic $ZH$ region by splitting on lepton multiplicity that should help this to decorrelate further.

A limit is also placed on the $tH$ cross-section using the $CL_{s}$ method (\ref{cite:CLs}). The limit is found to be 8.2 times the Standard Model expectation, stronger than the limit placed in the CP analysis. 

\subsection{STXS} \label{sec:STXS}

In order to avoid large uncertainties and correlations (computed from SM expectation using post-fit Asimov), several of the 44 STXS truth bins are merged in a so-called "strong merging scheme" resulting in 27 truth bins being targeted. The merging is as follows:

\begin{itemize}
\item For $gg\rightarrow H$, the four bins in regions of $350 GeV < m_{jj} < 700 GeV$ and $m_{jj}> 700 GeV$ are merged into a single $m_{jj} > 350 GeV$ bin. The $p_{T}^{H} > 650 GeV$ bin is also merged with the $450 GeV < p_{T}^{H} < 650 GeV$ bin into a single $p_{T}^{H} > 450 GeV$ bin. The splits at $p_{T}^{Hjj}=25 GeV$ are removed.
\item For $qq' \rightarrow Hqq'$ processes, the 0-jet and 1-jet regions are combined, as are the regions corresponding to $m_{jj} < 60 GeV$ and $120 GeV < m_{jj} < 350 GeV$. The splits at $p_{T}^{Hjj}=25 GeV$ are removed, and a single  $p_{T}^{H} > 200 GeV$ region is also defined by merging together the two regions corresponding to $350 GeV < m_{jj}<700 GeV$ and $m_{jj}>700 GeV$.
\item In both the $qq \rightarrow WH$ and $pp \rightarrow ZH$ processes, only the two regions $p_{T}^{V} < 150 GeV$ and $p_{T}^{V} > 150 GeV$ are retained.
\item In the $ttH$ process, the $200 GeV < p_{T}^{H} < 300 GeV$ and $p_{T}^{H} > 300 GeV$ regions are combined into a single $p_{T}^{H} > 200 GeV$ region.
\item The $tWH$ and $tHjb$ regions are merged into a single $tH$ region.
\end{itemize}

As in the other schemes, $(\sigma \times B_{\gamma \gamma})$ is measured for each of the 27 truth regions. Results are shown in Table XXX and Figure XXX. The correlation matrix is shown in Figure XXX. All categories are statistically limited, and no substantial deviation from the Standard Model is observed.

